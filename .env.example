LLM_MODEL="gemini/gemini-2.0-flash-lite-preview-02-05"
# Other options, all supported by https://github.com/BerriAI/litellm:
# These don't require setting a key, but probably modifying the code to set the api_base: https://docs.litellm.ai/docs/providers/ollama'
# - ollama/deepseek-r1
# - ollama/phi4
# These require setting OPENAI_API_KEY env. (Others: https://platform.openai.com/docs/pricing):
# - openai/gpt-4o-mini
# - openai/o3-mini-2025-01-31

# required by default LLM_MODEL, Gemini
GEMINI_API_KEY="giberish-key"

# cc-nc license
LLM_RERANKER="corrius/cross-encoder-mmarco-mMiniLMv2-L12-H384-v1"
RERANKER_MODEL_TYPE="cross-encoder"
# Other multilingual options:
# - model_type=cross-encoder - model=jinaai/jina-reranker-v2-base-multilingual
# - model_type=cross-encoder - model=cross-encoder/mmarco-mMiniLMv2-L12-H384-v1 (just 14 languages)
# - model_type=cross-encoder - model=BAAI/bge-reranker-v2-m3
# - model_type=cross-encoder - model=Alibaba-NLP/gte-multilingual-reranker-base
# Best flashrank model (no GPU, good on CPU) (probably requires other dependencies... check rerankers docs):
# - ms-marco-MultiBERT-L-12
# FlashRank multilingual models:
# - model_type=flashrank - model=ms-marco-MultiBERT-L-12, probably requires installing other dependencies
# - jina multilingual (current) supports ONNX, but I'm not sure how to use it with rerankers, probably doesn't work
#   since https://github.com/PrithivirajDamodaran/FlashRank doesn't support it
